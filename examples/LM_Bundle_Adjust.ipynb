{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from plio.io import io_controlnetwork\n",
    "from knoten.csm import create_csm\n",
    "from scipy import sparse\n",
    "import ale\n",
    "import csmapi\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from knoten.bundle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Network and Generate Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = '/scratch/csm2020/data/cubes2.lis'\n",
    "sensors = generate_sensors(cubes)\n",
    "\n",
    "network = '/scratch/csm2020/data/hand_dense.net'\n",
    "cnet = io_controlnetwork.from_isis(network)\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # autoseed did not generate ground points, calculate and repopulate the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Which Sensor Parameters to Solve For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "Image: MRO/CTX/1085197697:073\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n",
      "Image: MRO/CTX/1096561308:045\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n",
      "Image: MRO/CTX/1136952576:186\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n",
      "Image: MRO/CTX/1157902986:250\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n"
     ]
    }
   ],
   "source": [
    "all_parameters = {sn: get_sensor_parameters(sensor) for sn, sensor in sensors.items()}\n",
    "for sn, parameters in all_parameters.items():\n",
    "    print(f\"Image: {sn}\")\n",
    "    for param in parameters:\n",
    "        print(f\"  {param.name} | {param.index} | {param.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve for angles and angular rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_parameters = {sn: params[6:12] for sn, params in all_parameters.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Column Indices for Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('MRO/CTX/1085197697:073', (0, 6)), ('MRO/CTX/1157902986:250', (6, 12)), ('MRO/CTX/1096561308:045', (12, 18)), ('MRO/CTX/1136952576:186', (18, 24)), ('autoseed_001', (24, 27)), ('autoseed_002', (27, 30)), ('autoseed_003', (30, 33)), ('autoseed_004', (33, 36)), ('autoseed_005', (36, 39)), ('autoseed_006', (39, 42)), ('autoseed_007', (42, 45)), ('autoseed_008', (45, 48)), ('autoseed_009', (48, 51)), ('autoseed_010', (51, 54)), ('autoseed_011', (54, 57)), ('autoseed_012', (57, 60)), ('autoseed_013', (60, 63)), ('autoseed_014', (63, 66)), ('autoseed_015', (66, 69)), ('autoseed_016', (69, 72)), ('autoseed_017', (72, 75)), ('autoseed_018', (75, 78)), ('autoseed_019', (78, 81)), ('hand_01', (81, 84)), ('hand_02', (84, 87)), ('hand_03', (87, 90)), ('hand_04', (90, 93)), ('hand_05', (93, 96)), ('hand_06', (96, 99)), ('hand_07', (99, 102)), ('hand_08', (102, 105)), ('hand_09', (105, 108)), ('hand_10', (108, 111)), ('hand_11', (111, 114)), ('hand_12', (114, 117)), ('hand_13', (117, 120)), ('hand_14', (120, 123)), ('hand_15', (123, 126)), ('hand_16', (126, 129))])\n"
     ]
    }
   ],
   "source": [
    "column_dict = compute_coefficient_columns(cnet, sensors, solve_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the Weight Matrix\n",
    "#### According to the weighted Normal equation (J.TWJ), W needs to be a square matrix the size of (# of measures)x2. So it is the weight of the observations. In ISIS, the weight of the observations are an inverted function of the size of the pixels on the focal plane (resolution). However, in csm we do not have access to that information. \n",
    "#### For the time being, since we are working exclusively with CTX images we are going to set the weight matrix equal to the identity matrix -> all observations have the same weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = 2 * len(cnet)\n",
    "W_observations = np.eye(num_observations) # this is a place holder until Jesse adds his calculations\n",
    "W_params = compute_parameter_weights(cnet, sensors, solve_parameters, column_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Initial Sigma0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigma(V, dX, W_parameters, W_observations):\n",
    "    \"\"\"\n",
    "    Computes the resulting standard deviation of the residuals for the current state of the bundle network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    V  :  np.array\n",
    "          An array of residuals of the difference between registered measure \n",
    "          and back projected ground points in image space.\n",
    "    W_parameters  :  ndarray \n",
    "                     The parameter weight matrix (i.e.: sensor parameters and point weights)\n",
    "    W_observations  :  ndarray\n",
    "                     The observation weight matrix (i.e.: point weights)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "       : float64\n",
    "         Standard deviation of the residuals\n",
    "    \"\"\"\n",
    "    num_parameters = W_parameters.shape[0]\n",
    "    num_observations = W_observations.shape[0]\n",
    "    dof = num_observations - num_parameters\n",
    "    VTPV = V.dot(W_observations).dot(V) + dX.dot(W_parameters).dot(dX)\n",
    "    sigma0 = np.sqrt(VTPV/dof)\n",
    "    return sigma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Sensors and Ground Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(sensors, parameters, network, updates, coefficient_columns):\n",
    "    \"\"\"\n",
    "    Updates the sensor objects parameter values and the ground point values in the \n",
    "    networks DataFrame. The update occurs directly to variables, so nothing is returned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sensors  :  dict\n",
    "                A dictionary that maps ISIS serial numbers to CSM sensors\n",
    "    parameters :  list\n",
    "                  The list of  CsmParameter to compute the partials W.R.T.\n",
    "    network  :  DataFrame\n",
    "                The control network as a dataframe generated by plio.\n",
    "    updates   : np.ndarray\n",
    "                An array of updated parameter values\n",
    "    coefficient_columns:  OrderedDict\n",
    "                          Dictionary that maps serial numbers and point IDs to\n",
    "                          the column range their parameters are in the Jacobian\n",
    "                          matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    # update the sensor partials\n",
    "    for sn, sensor in sensors.items():\n",
    "        for i, param in enumerate(parameters[sn]):\n",
    "            if i > coefficient_columns[sn][1]:\n",
    "                print('THIS SHOULD BE AN ACTUAL ERROR')\n",
    "            current_value = sensor.getParameterValue(param.index)\n",
    "            sensor.setParameterValue(param.index, current_value+updates[coefficient_columns[sn][0]+i])\n",
    "\n",
    "    # update ground points\n",
    "    for _, row in network.iterrows():\n",
    "        point_id = row['id']\n",
    "        ground_pt = row[['adjustedX', 'adjustedY', 'adjustedZ']].values\n",
    "        adj = updates[coefficient_columns[point_id][0]:coefficient_columns[point_id][1]] \n",
    "        network.loc[network.id == point_id, [\"adjustedX\", \"adjustedY\", \"adjustedZ\"]] = ground_pt + adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole bundle process in a loop without LM terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "OrderedDict([('MRO/CTX/1085197697:073', (0, 6)), ('MRO/CTX/1157902986:250', (6, 12)), ('MRO/CTX/1096561308:045', (12, 18)), ('MRO/CTX/1136952576:186', (18, 24)), ('autoseed_001', (24, 27)), ('autoseed_002', (27, 30)), ('autoseed_003', (30, 33)), ('autoseed_004', (33, 36)), ('autoseed_005', (36, 39)), ('autoseed_006', (39, 42)), ('autoseed_007', (42, 45)), ('autoseed_008', (45, 48)), ('autoseed_009', (48, 51)), ('autoseed_010', (51, 54)), ('autoseed_011', (54, 57)), ('autoseed_012', (57, 60)), ('autoseed_013', (60, 63)), ('autoseed_014', (63, 66)), ('autoseed_015', (66, 69)), ('autoseed_016', (69, 72)), ('autoseed_017', (72, 75)), ('autoseed_018', (75, 78)), ('autoseed_019', (78, 81)), ('hand_01', (81, 84)), ('hand_02', (84, 87)), ('hand_03', (87, 90)), ('hand_04', (90, 93)), ('hand_05', (93, 96)), ('hand_06', (96, 99)), ('hand_07', (99, 102)), ('hand_08', (102, 105)), ('hand_09', (105, 108)), ('hand_10', (108, 111)), ('hand_11', (111, 114)), ('hand_12', (114, 117)), ('hand_13', (117, 120)), ('hand_14', (120, 123)), ('hand_15', (123, 126)), ('hand_16', (126, 129))])\n",
      "iteration 0: sigma0 = 0.3837893449537876\n",
      "\n",
      "corrections: mean = -0.0001342638023296754 min = -0.2479461207727384 max = 0.26985669005441637\n",
      "iteration 1: sigma0 = 0.3836877508419455\n",
      "\n",
      "corrections: mean = -4.746452049891667e-08 min = -4.821248973139848e-06 max = 3.4508974134037083e-06\n",
      "iteration 2: sigma0 = 0.38360265958749135\n",
      "\n",
      "corrections: mean = 1.6341450280976616e-11 min = -4.658701549862284e-10 max = 1.0794691548201729e-09\n",
      "iteration 3: sigma0 = 0.38360265958575535\n",
      "\n",
      "change in sigma0 of 1.736000232455126e-12 converged!\n"
     ]
    }
   ],
   "source": [
    "## sensors = generate_sensors(cubes) # generate sensors\n",
    "cnet = io_controlnetwork.from_isis(network) # load in network\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # calculate ground points\n",
    "\n",
    "### INPUTS ###\n",
    "all_parameters = {sn: get_sensor_parameters(sensor) for sn, sensor in sensors.items()} #all parameters\n",
    "parameters = {sn: parameter[6:12] for sn, parameter in all_parameters.items()} #just solving for camera angles and angle velocity\n",
    "##############\n",
    "\n",
    "column_dict = compute_coefficient_columns(cnet, sensors, parameters)\n",
    "num_parameters = max(col_range[1] for col_range in column_dict.values())\n",
    "num_observations = 2 * len(cnet)\n",
    "W_observations = np.eye(num_observations)\n",
    "W_params = compute_parameter_weights(cnet, sensors, parameters, column_dict)\n",
    "\n",
    "iteration = 0\n",
    "V = compute_residuals(cnet, sensors)\n",
    "dX = np.zeros(W_params.shape[0]) #initialize for sigma calculatio\n",
    "sigma0 = compute_sigma(V, dX, W_params, W_observations)\n",
    "print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "\n",
    "max_iterations = 100\n",
    "tol = 1e-10\n",
    "total_correction = np.zeros(num_parameters)\n",
    "damping = 0.1\n",
    "for i in range(max_iterations):   \n",
    "    iteration += 1\n",
    "    old_sigma0 = sigma0\n",
    "    \n",
    "    J = compute_jacobian(cnet, sensors, parameters, column_dict)    \n",
    "    N = J.T.dot(W_observations).dot(J) + W_params # calculate the normal equation\n",
    "    C = J.T.dot(W_observations).dot(V) - W_params.dot(total_correction)\n",
    "    dX = np.linalg.inv(N).dot(C) # calculate change in camera parameters and ground points\n",
    "    \n",
    "\n",
    "    total_correction += dX\n",
    "    print(f'corrections: mean = {dX.mean()} min = {dX.min()} max = {dX.max()}')\n",
    "    \n",
    "    update_parameters(sensors, parameters, cnet, dX, column_dict)\n",
    "    \n",
    "    V = compute_residuals(cnet, sensors)\n",
    "    sigma0 = compute_sigma(V, dX, W_params, W_observations)\n",
    "#     sigma0 = np.sqrt((V.dot(W_observations).dot(V) + dX.dot(W_params).dot(dX))/dof)\n",
    "    if (sigma0 < old_sigma0): #good, do we really want to make the step size smaller? \n",
    "        damping*=0.1\n",
    "    else:\n",
    "        damping*=10\n",
    "        \n",
    "    print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "    \n",
    "    if (abs(sigma0 - old_sigma0) < tol):\n",
    "        print(f'change in sigma0 of {abs(sigma0 - old_sigma0)} converged!')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole (Dense) Bundle Process in a loop with LM terms\n",
    "\n",
    "The next three cells show examples of the bundle adjustment loop running with Levenberg-Marquat added.\n",
    "\n",
    "This example shows the first heuristic for initializing $\\lambda$, the weighting parameter, from Numerical Recipes in C++\n",
    "\n",
    "NumericalRecipes in C++ recommended starting with $\\lambda$ = 0.01, and then increasing or decreasing this value by an order of magnitude each iteration depending on whether the last iteration increased or decreased \n",
    "$\\sigma_0$.\n",
    "\n",
    "Step sizes will get smaller as the target is approached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM using Numerical Recipies's heuristic\n",
    "\n",
    "$\\lambda = 0.01$ to start out, then increased or decreased by an order of magnitude each step. \n",
    "\n",
    "`damping` is used as the variable for $\\lambda$, since in python `lambda` is a reserved word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "OrderedDict([('MRO/CTX/1085197697:073', (0, 6)), ('MRO/CTX/1157902986:250', (6, 12)), ('MRO/CTX/1096561308:045', (12, 18)), ('MRO/CTX/1136952576:186', (18, 24)), ('autoseed_001', (24, 27)), ('autoseed_002', (27, 30)), ('autoseed_003', (30, 33)), ('autoseed_004', (33, 36)), ('autoseed_005', (36, 39)), ('autoseed_006', (39, 42)), ('autoseed_007', (42, 45)), ('autoseed_008', (45, 48)), ('autoseed_009', (48, 51)), ('autoseed_010', (51, 54)), ('autoseed_011', (54, 57)), ('autoseed_012', (57, 60)), ('autoseed_013', (60, 63)), ('autoseed_014', (63, 66)), ('autoseed_015', (66, 69)), ('autoseed_016', (69, 72)), ('autoseed_017', (72, 75)), ('autoseed_018', (75, 78)), ('autoseed_019', (78, 81)), ('hand_01', (81, 84)), ('hand_02', (84, 87)), ('hand_03', (87, 90)), ('hand_04', (90, 93)), ('hand_05', (93, 96)), ('hand_06', (96, 99)), ('hand_07', (99, 102)), ('hand_08', (102, 105)), ('hand_09', (105, 108)), ('hand_10', (108, 111)), ('hand_11', (111, 114)), ('hand_12', (114, 117)), ('hand_13', (117, 120)), ('hand_14', (120, 123)), ('hand_15', (123, 126)), ('hand_16', (126, 129))])\n",
      "iteration 0: sigma0 = 0.3834809139528003\n",
      "\n",
      "corrections: mean = 3.0722099425394215e-07 min = -8.081483675221561e-05 max = 8.913008869003753e-05\n",
      "iteration 1: sigma0 = 0.3834807128262849\n",
      "\n",
      "corrections: mean = 1.8448139496166514e-06 min = -0.0006744397218927234 max = 0.0006311653619091981\n",
      "iteration 2: sigma0 = 0.3834793522224133\n",
      "\n",
      "corrections: mean = -1.6448430165127127e-05 min = -0.006259928830596483 max = 0.006277234051022338\n",
      "iteration 3: sigma0 = 0.38347316881329274\n",
      "\n",
      "corrections: mean = -9.729090103980444e-05 min = -0.043873217593182974 max = 0.05020831936969662\n",
      "iteration 4: sigma0 = 0.38344720841227964\n",
      "\n",
      "corrections: mean = -3.4431393648009435e-05 min = -0.10353090458980926 max = 0.12256234990803173\n",
      "iteration 5: sigma0 = 0.3834009546378761\n",
      "\n",
      "corrections: mean = -7.874567579582659e-07 min = -0.047459113242319884 max = 0.04811283437216138\n",
      "iteration 6: sigma0 = 0.38336874896690964\n",
      "\n",
      "corrections: mean = -1.0811607997045452e-07 min = -0.006589208230282579 max = 0.006256017754636698\n",
      "iteration 7: sigma0 = 0.38336379718944824\n",
      "\n",
      "corrections: mean = -1.2410151661434289e-08 min = -0.0006846136434108924 max = 0.0006444490294294532\n",
      "iteration 8: sigma0 = 0.3833634726322458\n",
      "\n",
      "corrections: mean = -1.2621809061683805e-09 min = -6.87286093893794e-05 max = 6.46395672752282e-05\n",
      "iteration 9: sigma0 = 0.3833634435849249\n",
      "\n",
      "corrections: mean = -1.2719068762773128e-10 min = -6.875558894845864e-06 max = 6.46501388847706e-06\n",
      "iteration 10: sigma0 = 0.38336344071468026\n",
      "\n",
      "corrections: mean = -1.095976326404826e-11 min = -6.865779050542945e-07 max = 6.472822250495515e-07\n",
      "iteration 11: sigma0 = 0.38336344042918163\n",
      "\n",
      "corrections: mean = 3.373646625496664e-13 min = -6.901584048236878e-08 max = 6.471173653807224e-08\n",
      "iteration 12: sigma0 = 0.3833634404029933\n",
      "\n",
      "change in sigma0 of 2.618832928291681e-11 converged!\n"
     ]
    }
   ],
   "source": [
    "## sensors = generate_sensors(cubes) # generate sensors\n",
    "cnet = io_controlnetwork.from_isis(network) # load in network\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # calculate ground points\n",
    "\n",
    "### INPUTS ###\n",
    "all_parameters = {sn: get_sensor_parameters(sensor) for sn, sensor in sensors.items()} #all parameters\n",
    "parameters = {sn: parameter[6:12] for sn, parameter in all_parameters.items()} #just solving for camera angles and angle velocity\n",
    "##############\n",
    "\n",
    "column_dict = compute_coefficient_columns(cnet, sensors, parameters)\n",
    "num_parameters = max(col_range[1] for col_range in column_dict.values())\n",
    "num_observations = 2 * len(cnet)\n",
    "W_observations = np.eye(num_observations)\n",
    "W_params = compute_parameter_weights(cnet, sensors, parameters, column_dict)\n",
    "\n",
    "iteration = 0\n",
    "V = compute_residuals(cnet, sensors)\n",
    "dX = np.zeros(W_params.shape[0]) #initialize for sigma calculatio\n",
    "sigma0 = compute_sigma(V, dX, W_params, W_observations)\n",
    "print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "\n",
    "max_iterations = 100\n",
    "tol = 1e-10\n",
    "total_correction = np.zeros(num_parameters)\n",
    "damping = 100\n",
    "for i in range(max_iterations):   \n",
    "    iteration += 1\n",
    "    old_sigma0 = sigma0\n",
    "    \n",
    "    J = compute_jacobian(cnet, sensors, parameters, column_dict)    \n",
    "    C = J.T.dot(W_observations).dot(V) - damping*np.identity(W_params.shape[0]).dot(total_correction) - W_params.dot(total_correction)\n",
    "    N = J.T.dot(W_observations).dot(J) + damping*np.identity(W_params.shape[0]) + W_params\n",
    "    dX = np.linalg.inv(N).dot(C) # calculate change in camera parameters and ground points\n",
    "    \n",
    "    total_correction += dX\n",
    "    print(f'corrections: mean = {dX.mean()} min = {dX.min()} max = {dX.max()}')\n",
    "    \n",
    "    update_parameters(sensors, parameters, cnet, dX, column_dict)\n",
    "    \n",
    "    V = compute_residuals(cnet, sensors)\n",
    "    sigma0 = compute_sigma(V, dX, W_params, W_observations)\n",
    "    if (sigma0 < old_sigma0):\n",
    "        damping*=0.1\n",
    "    else:\n",
    "        damping*=10\n",
    "        \n",
    "    print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "    \n",
    "    if (abs(sigma0 - old_sigma0) < tol):\n",
    "        print(f'change in sigma0 of {abs(sigma0 - old_sigma0)} converged!')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sba/levmar's heuristic\n",
    "\n",
    "$\\lambda$ initially set to a user supplied value (or default = 0.001) * the max value in $J^{T}J$\n",
    "\n",
    "Updates either:\n",
    "\n",
    "(1) $\\lambda = max(1/3, 1-(2\\rho -1)^3) , \\nu = 2.0$\n",
    "\n",
    "(2) $\\lambda = \\lambda\\nu, \\nu = 2.0\\nu$\n",
    "\n",
    "See: http://users.ics.forth.gr/~argyros/mypapers/2004_08_tr340_forth_sba.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)\n",
      "OrderedDict([('MRO/CTX/1085197697:073', (0, 6)), ('MRO/CTX/1157902986:250', (6, 12)), ('MRO/CTX/1096561308:045', (12, 18)), ('MRO/CTX/1136952576:186', (18, 24)), ('autoseed_001', (24, 27)), ('autoseed_002', (27, 30)), ('autoseed_003', (30, 33)), ('autoseed_004', (33, 36)), ('autoseed_005', (36, 39)), ('autoseed_006', (39, 42)), ('autoseed_007', (42, 45)), ('autoseed_008', (45, 48)), ('autoseed_009', (48, 51)), ('autoseed_010', (51, 54)), ('autoseed_011', (54, 57)), ('autoseed_012', (57, 60)), ('autoseed_013', (60, 63)), ('autoseed_014', (63, 66)), ('autoseed_015', (66, 69)), ('autoseed_016', (69, 72)), ('autoseed_017', (72, 75)), ('autoseed_018', (75, 78)), ('autoseed_019', (78, 81)), ('hand_01', (81, 84)), ('hand_02', (84, 87)), ('hand_03', (87, 90)), ('hand_04', (90, 93)), ('hand_05', (93, 96)), ('hand_06', (96, 99)), ('hand_07', (99, 102)), ('hand_08', (102, 105)), ('hand_09', (105, 108)), ('hand_10', (108, 111)), ('hand_11', (111, 114)), ('hand_12', (114, 117)), ('hand_13', (117, 120)), ('hand_14', (120, 123)), ('hand_15', (123, 126)), ('hand_16', (126, 129))])\n",
      "iteration 0: sigma0 = 0.3832173540381217\n",
      "\n",
      "corrections: mean = -0.00016332740493045064 min = -0.15286139184623282 max = 0.17783547906579963\n",
      "DAMPING1: 1.8380209192674248 NU1: 2\n",
      "iteration 1: sigma0 = 0.38318068148639156\n",
      "\n",
      "corrections: mean = 0.00015227618084876626 min = -0.1749449695865202 max = 0.149613542962322\n",
      "DAMPING2: 3.6760418385348497 NU2: 4\n",
      "iteration 2: sigma0 = 0.38323976044675184\n",
      "\n",
      "corrections: mean = 8.403007451931818e-06 min = -0.0014563314244338769 max = 0.0015810699012601642\n",
      "DAMPING1: 0.3333333333333333 NU1: 2\n",
      "iteration 3: sigma0 = 0.3832143142885875\n",
      "\n",
      "corrections: mean = -7.409940267650626e-05 min = -0.013780550910003703 max = 0.01429262878290048\n",
      "DAMPING1: 1.4159043929431536 NU1: 2\n",
      "iteration 4: sigma0 = 0.3832056292435121\n",
      "\n",
      "corrections: mean = 6.0080569860125926e-05 min = -0.011964065384286094 max = 0.011289115316835815\n",
      "DAMPING2: 2.8318087858863072 NU2: 4\n",
      "iteration 5: sigma0 = 0.38321229315133737\n",
      "\n",
      "corrections: mean = 1.1792567756915409e-05 min = -0.0018959496702426815 max = 0.002012100886008782\n",
      "DAMPING2: 11.327235143545229 NU2: 8\n",
      "iteration 6: sigma0 = 0.38321375022124776\n",
      "\n",
      "corrections: mean = 5.197117769611707e-06 min = -0.0014049780613722275 max = 0.001594278886409165\n",
      "DAMPING2: 90.61788114836183 NU2: 16\n",
      "iteration 7: sigma0 = 0.38321620833702347\n",
      "\n",
      "corrections: mean = -2.0761162824668405e-07 min = -0.0005547274116475284 max = 0.0004822260426818242\n",
      "DAMPING2: 1449.8860983737893 NU2: 32\n",
      "iteration 8: sigma0 = 0.383217233778271\n",
      "\n",
      "corrections: mean = -1.072890107327697e-07 min = -9.19158094584082e-05 max = 8.309899239861605e-05\n",
      "DAMPING2: 46396.35514796126 NU2: 64\n",
      "iteration 9: sigma0 = 0.3832173434741144\n",
      "\n",
      "corrections: mean = -7.492656149549743e-09 min = -6.1160640672464755e-06 max = 5.5800441722033985e-06\n",
      "DAMPING2: 2969366.7294695205 NU2: 128\n",
      "iteration 10: sigma0 = 0.3832173536344936\n",
      "\n",
      "corrections: mean = -2.389912243104664e-10 min = -1.9457860071311811e-07 max = 1.776308974346147e-07\n",
      "DAMPING2: 380078941.3720986 NU2: 256\n",
      "iteration 11: sigma0 = 0.38321735403147983\n",
      "\n",
      "corrections: mean = -3.764399841808002e-12 min = -3.0646019137841403e-09 max = 2.797728603834513e-09\n",
      "DAMPING2: 97300208991.25725 NU2: 512\n",
      "iteration 12: sigma0 = 0.38321735403387136\n",
      "\n",
      "change in sigma0 of 2.3915314173450497e-12 converged!\n"
     ]
    }
   ],
   "source": [
    "## sensors = generate_sensors(cubes) # generate sensors\n",
    "cnet = io_controlnetwork.from_isis(network) # load in network\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # calculate ground points\n",
    "\n",
    "### INPUTS ###\n",
    "all_parameters = {sn: get_sensor_parameters(sensor) for sn, sensor in sensors.items()} #all parameters\n",
    "parameters = {sn: parameter[6:12] for sn, parameter in all_parameters.items()} #just solving for camera angles and angle velocity\n",
    "##############\n",
    "\n",
    "column_dict = compute_coefficient_columns(cnet, sensors, parameters)\n",
    "num_parameters = max(col_range[1] for col_range in column_dict.values())\n",
    "num_observations = 2 * len(cnet)\n",
    "W_observations = np.eye(num_observations)\n",
    "W_params = compute_parameter_weights(cnet, sensors, parameters, column_dict)\n",
    "\n",
    "iteration = 0\n",
    "V = compute_residuals(cnet, sensors)\n",
    "dX = np.zeros(W_params.shape[0]) #initialize for sigma calculatio\n",
    "sigma0 = compute_sigma(V, dX, W_params, W_observations)\n",
    "print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "\n",
    "max_iterations = 100\n",
    "tol = 1e-10\n",
    "total_correction = np.zeros(num_parameters)\n",
    "damping = 0.001\n",
    "for i in range(max_iterations):   \n",
    "    iteration += 1\n",
    "    old_sigma0 = sigma0\n",
    "    \n",
    "    J = compute_jacobian(cnet, sensors, parameters, column_dict)\n",
    "    if i==0:\n",
    "        damping *= np.max(J.T.dot(J))\n",
    "    \n",
    "    C = J.T.dot(W_observations).dot(V) - damping*np.identity(W_params.shape[0]).dot(total_correction) - W_params.dot(total_correction)\n",
    "    N = J.T.dot(W_observations).dot(J) + damping*np.identity(W_params.shape[0]) + W_params\n",
    "#    N = J.T.dot(W_observations).dot(J) + damping*W_params\n",
    "#    C = J.T.dot(W_observations).dot(V) - damping*W_params.dot(total_correction) #different :D\n",
    "    dX = np.linalg.inv(N).dot(C) # calculate change in camera parameters and ground points\n",
    "    \n",
    "\n",
    "    total_correction += dX\n",
    "    print(f'corrections: mean = {dX.mean()} min = {dX.min()} max = {dX.max()}')\n",
    "    \n",
    "    update_parameters(sensors, parameters, cnet, dX, column_dict)\n",
    "    \n",
    "    old_V = V\n",
    "    V = compute_residuals(cnet, sensors)\n",
    "    sigma0 = compute_sigma(V, dX, W_params, W_observations)\n",
    "    if (sigma0 < old_sigma0):\n",
    "        damping = max(1.0/3.0, (np.linalg.norm(old_V)**2 - np.linalg.norm(V)**2)/(dX.T.dot(damping*dX + C)))\n",
    "        nu = 2\n",
    "        print(\"DAMPING1:\", damping, \"NU1:\", nu)\n",
    "    else:\n",
    "        damping = damping * nu\n",
    "        nu = 2 * nu\n",
    "        print(\"DAMPING2:\", damping, \"NU2:\", nu)\n",
    "\n",
    "    print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "    \n",
    "    if (abs(sigma0 - old_sigma0) < tol):\n",
    "        print(f'change in sigma0 of {abs(sigma0 - old_sigma0)} converged!')\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
